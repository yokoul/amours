#!/usr/bin/env python3
"""
Script de test pour les trois fichiers audio avec optimisation GPU et dÃ©tection d'intervenants.
Lance automatiquement la transcription de tous les fichiers avec analyse des intervenants.
"""

import sys
import os
from pathlib import Path
import torch

# Ajouter le rÃ©pertoire src au path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))


def check_gpu_availability():
    """VÃ©rifie la disponibilitÃ© des GPU."""
    print("ğŸ” VÃ©rification des dispositifs disponibles :")
    
    # PyTorch version
    print(f"ğŸ“¦ PyTorch version : {torch.__version__}")
    
    # CPU
    print("âœ… CPU disponible")
    
    # CUDA (NVIDIA)
    if torch.cuda.is_available():
        print(f"âœ… CUDA disponible - {torch.cuda.device_count()} GPU(s)")
        for i in range(torch.cuda.device_count()):
            print(f"   GPU {i}: {torch.cuda.get_device_name(i)}")
        return "cuda"
    else:
        print("âŒ CUDA non disponible")
    
    # MPS (Apple Silicon)
    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        print("âœ… MPS (Metal Performance Shaders) disponible - GPU Apple Silicon")
        return "mps"
    else:
        print("âŒ MPS non disponible")
    
    return "cpu"


def install_missing_dependencies():
    """Installe les dÃ©pendances manquantes pour la dÃ©tection d'intervenants."""
    print("ğŸ“¦ VÃ©rification des dÃ©pendances...")
    
    try:
        import pyannote.audio
        print("âœ… pyannote.audio disponible")
        return True
    except ImportError:
        print("âš ï¸  pyannote.audio non disponible")
        print("ğŸ’¡ Installation recommandÃ©e : pip install pyannote.audio")
        
        # Continuer sans dÃ©tection d'intervenants
        return False


def test_transcription_with_gpu():
    """Lance les tests de transcription avec optimisation GPU."""
    
    # VÃ©rifier la disponibilitÃ© du GPU
    optimal_device = check_gpu_availability()
    
    # VÃ©rifier les dÃ©pendances
    diarization_available = install_missing_dependencies()
    
    print(f"\nğŸš€ Configuration de test :")
    print(f"   â€¢ Dispositif optimal : {optimal_device}")
    print(f"   â€¢ DÃ©tection d'intervenants : {'Oui' if diarization_available else 'Non (continuer sans)'}")
    print("=" * 70)
    
    # CrÃ©er le dossier de sortie
    output_dir = Path("output")
    output_dir.mkdir(exist_ok=True)
    
    # Lister les fichiers audio disponibles
    audio_dir = Path("audio")  # Chemin depuis la racine du projet
    audio_files = []
    
    # Rechercher tous les fichiers audio, y compris ceux avec des espaces
    if audio_dir.exists():
        for file_path in audio_dir.iterdir():
            if file_path.is_file() and file_path.suffix.lower() in ['.mp3', '.wav', '.m4a', '.flac', '.ogg']:
                audio_files.append(file_path)
    
    if not audio_files:
        print("âŒ Aucun fichier audio trouvÃ© dans le dossier 'audio/'")
        return
    
    print(f"ğŸµ Fichiers audio trouvÃ©s : {len(audio_files)}")
    for f in audio_files:
        print(f"   â€¢ {f.name}")
    
    print("\n" + "=" * 70)
    
    # Importer les modules aprÃ¨s vÃ©rification
    try:
        if diarization_available:
            from transcriber_with_speakers import AudioTranscriberWithSpeakers as Transcriber
            transcribe_method = "transcribe_with_speakers"
        else:
            from transcriber import AudioTranscriber as Transcriber
            transcribe_method = "transcribe_with_timestamps"
        
        from export import ExportManager
        
    except ImportError as e:
        print(f"âŒ Erreur d'import : {e}")
        return
    
    # Traiter chaque fichier
    results = []
    
    for i, audio_file in enumerate(audio_files, 1):
        print(f"\nğŸµ FICHIER {i}/{len(audio_files)} : {audio_file.name}")
        print("=" * 70)
        
        try:
            # Initialiser le transcripteur
            if diarization_available:
                transcriber = Transcriber(
                    model_name="medium",
                    language="fr", 
                    device=optimal_device if optimal_device != "cpu" else None,
                    enable_diarization=True,
                    verbose=False
                )
            else:
                transcriber = Transcriber(
                    model_name="medium",
                    language="fr",
                    device=optimal_device if optimal_device != "cpu" else None,
                    verbose=False  
                )
            
            # Transcription
            print("ğŸ”„ Transcription en cours...")
            
            if diarization_available:
                result = transcriber.transcribe_with_speakers(
                    str(audio_file),
                    word_timestamps=True
                )
            else:
                result = transcriber.transcribe_with_timestamps(
                    str(audio_file), 
                    word_timestamps=True
                )
            
            # GÃ©nÃ©rer un nom de fichier de sortie propre
            output_name = audio_file.stem.lower().replace(" ", "_")
            
            # Export
            export_manager = ExportManager()
            
            # JSON complet
            json_file = output_dir / f"{output_name}_complete.json"
            export_manager.export_json(result, str(json_file))
            
            # CSV pour analyse
            csv_file = output_dir / f"{output_name}_data.csv"
            export_manager.export_csv(result, str(csv_file))
            
            # Format artistique
            artistic_file = output_dir / f"{output_name}_artistic.json"
            export_manager.export_artistic_format(result, str(artistic_file))
            
            # Sous-titres
            srt_file = output_dir / f"{output_name}_subtitles.srt"
            if diarization_available:
                export_srt_with_speakers(result, str(srt_file))
            else:
                export_manager.export_srt_subtitles(result, str(srt_file))
            
            # Statistiques
            print_stats(result, diarization_available)
            
            results.append((audio_file.name, result))
            
        except Exception as e:
            print(f"âŒ Erreur lors du traitement de {audio_file.name} : {e}")
            import traceback
            traceback.print_exc()
    
    # RÃ©sumÃ© final
    print_final_summary(results, diarization_available)


def export_srt_with_speakers(transcription_data, output_path):
    """Exporte SRT avec indication des intervenants."""
    try:
        def format_time(seconds):
            hours = int(seconds // 3600)
            minutes = int((seconds % 3600) // 60)
            secs = int(seconds % 60)
            millis = int((seconds % 1) * 1000)
            return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"
        
        with open(output_path, 'w', encoding='utf-8') as f:
            for i, segment in enumerate(transcription_data["transcription"]["segments"], 1):
                start_time = format_time(segment["start"])
                end_time = format_time(segment["end"])
                speaker = segment.get("speaker", "")
                text = segment["text"].strip()
                
                if speaker and speaker != "Inconnu":
                    text = f"[{speaker}] {text}"
                
                f.write(f"{i}\n{start_time} --> {end_time}\n{text}\n\n")
        
        print(f"ğŸ“º Sous-titres avec intervenants : {Path(output_path).name}")
        
    except Exception as e:
        print(f"âŒ Erreur export SRT : {e}")


def print_stats(result, with_speakers=False):
    """Affiche les statistiques de transcription."""
    metadata = result["metadata"]
    segments = result["transcription"]["segments"]
    
    print(f"\nğŸ“Š STATISTIQUES :")
    print(f"   â±ï¸  DurÃ©e : {metadata['duration']:.2f}s")
    print(f"   ğŸ–¥ï¸  Dispositif : {metadata.get('device', 'N/A')}")
    print(f"   ğŸ¬ Segments : {len(segments)}")
    
    if with_speakers and "speakers" in result:
        speakers = result["speakers"]
        print(f"   ğŸ‘¥ Intervenants : {len(speakers)}")
        
        if speakers:
            for speaker_id, info in speakers.items():
                percentage = (info['total_time'] / metadata['duration']) * 100
                print(f"      â€¢ {speaker_id}: {info['total_time']:.1f}s ({percentage:.1f}%)")
    
    # Compter les mots
    total_words = sum(len(seg.get("words", [])) for seg in segments)
    if total_words > 0:
        wpm = total_words / metadata['duration'] * 60
        print(f"   ğŸ”¤ Mots : {total_words} ({wpm:.1f} mots/min)")


def print_final_summary(results, with_speakers=False):
    """Affiche le rÃ©sumÃ© final."""
    print(f"\n{'='*70}")
    print(f"ğŸ“‹ RÃ‰SUMÃ‰ FINAL")
    print(f"{'='*70}")
    
    if not results:
        print("âŒ Aucun fichier traitÃ© avec succÃ¨s")
        return
    
    print(f"âœ… Fichiers traitÃ©s : {len(results)}")
    
    total_duration = sum(r[1]["metadata"]["duration"] for _, r in results)
    total_segments = sum(len(r[1]["transcription"]["segments"]) for _, r in results)
    
    print(f"â±ï¸  DurÃ©e totale : {total_duration:.1f}s")
    print(f"ğŸ¬ Segments totaux : {total_segments}")
    
    if with_speakers:
        total_speakers = sum(len(r[1].get("speakers", {})) for _, r in results)
        print(f"ğŸ‘¥ Intervenants dÃ©tectÃ©s : {total_speakers}")
    
    print(f"\nğŸ“ Fichiers gÃ©nÃ©rÃ©s dans 'output/' :")
    print(f"   â€¢ JSON complets avec mÃ©tadonnÃ©es")
    print(f"   â€¢ CSV pour analyse de donnÃ©es")
    print(f"   â€¢ Formats artistiques optimisÃ©s") 
    print(f"   â€¢ Sous-titres SRT {'avec intervenants' if with_speakers else ''}")
    
    print(f"\nğŸ¨ DonnÃ©es prÃªtes pour exploitation artistique !")
    print(f"{'='*70}")


def main():
    """Fonction principale."""
    print("ğŸµ TEST DE TRANSCRIPTION AUDIO OPTIMISÃ‰")
    print("ğŸš€ GPU + DÃ©tection d'intervenants + Export multi-formats")
    print("=" * 70)
    
    test_transcription_with_gpu()


if __name__ == "__main__":
    main()